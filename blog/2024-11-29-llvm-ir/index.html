<!DOCTYPE html><meta charset="utf-8"><meta content="width=device-width,initial-scale=1"name="viewport"><link href="/css/main.css"rel="stylesheet"><link href="/blog/feed.xml"rel="alternate"title="RSS Feed"type="application/atom+xml"><title>jank is now running on LLVM IR</title><meta content="jank is now running on LLVM IR"property="og:title"><meta content="Learn about jank generating LLVM IR instead of C++. See the startup time improvements. Gain insight into what the community has been up to. Sponsor jank!"property="og:description"><meta content="https://jank-lang.org/img/logo-text-dark.png"property="og:image"><link href="/img/favicon/apple-touch-icon.png"rel="apple-touch-icon"sizes="180x180"><link href="/img/favicon/32.png"rel="icon"sizes="32x32"type="image/png"><link href="/img/favicon/16.png"rel="icon"sizes="16x16"type="image/png"><link href="/img/favicon/site.webmanifest"rel="manifest"><style>.gg-bulb{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:16px;height:16px;border:2px solid;border-bottom-color:transparent;border-radius:100px}.gg-bulb::after,.gg-bulb::before{content:"";display:block;box-sizing:border-box;position:absolute}.gg-bulb::before{border-top:0;border-bottom-left-radius:18px;border-bottom-right-radius:18px;top:10px;border-bottom:2px solid transparent;box-shadow:0 5px 0 -2px,inset 2px 0 0 0,inset -2px 0 0 0,inset 0 -4px 0 -2px;width:8px;height:8px;left:2px}.gg-bulb::after{width:12px;height:2px;border-left:3px solid;border-right:3px solid;border-radius:2px;bottom:0;left:0}.gg-check-o{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:22px;height:22px;border:2px solid;border-radius:100px}.gg-check-o::after{content:"";display:block;box-sizing:border-box;position:absolute;left:3px;top:-1px;width:6px;height:10px;border-color:currentColor;border-width:0 2px 2px 0;border-style:solid;transform-origin:bottom left;transform:rotate(45deg)}.gg-comment{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:20px;height:16px;border:2px solid;border-bottom:0;box-shadow:-6px 8px 0 -6px,6px 8px 0 -6px}.gg-comment::after,.gg-comment::before{content:"";display:block;box-sizing:border-box;position:absolute;width:8px}.gg-comment::before{border:2px solid;border-top-color:transparent;border-bottom-left-radius:20px;right:4px;bottom:-6px;height:6px}.gg-comment::after{height:2px;background:currentColor;box-shadow:0 4px 0 0;left:4px;top:4px}.gg-git-fork{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:2px;height:14px;background:currentColor}.gg-git-fork::after,.gg-git-fork::before{content:"";display:block;box-sizing:border-box;position:absolute}.gg-git-fork::before{border-right:2px solid;border-bottom:2px solid;border-bottom-right-radius:4px;bottom:4px;width:8px;height:6px;left:0}.gg-git-fork::after{width:4px;height:4px;background:currentColor;box-shadow:0 12px 0 0,6px 2px 0 0;border-radius:100%;left:-1px;top:-1px}.gg-heart,.gg-heart::after{border:2px solid;border-top-left-radius:100px;border-top-right-radius:100px;width:10px;height:8px;border-bottom:0}.gg-heart{box-sizing:border-box;position:relative;transform:translate(calc(-10px / 2 * var(--ggs,1)),calc(-6px / 2 * var(--ggs,1))) rotate(-45deg) scale(var(--ggs,1));display:block}.gg-heart::after,.gg-heart::before{content:"";display:block;box-sizing:border-box;position:absolute}.gg-heart::after{right:-9px;transform:rotate(90deg);top:5px}.gg-heart::before{width:11px;height:11px;border-left:2px solid;border-bottom:2px solid;left:-2px;top:3px}.gg-home{background:linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 0 bottom/4px 2px,linear-gradient(to left,currentColor 5px,transparent 0) no-repeat right bottom/4px 2px;box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:18px;height:14px;border:2px solid;border-top:0;border-bottom:0;border-top-right-radius:3px;border-top-left-radius:3px;border-bottom-right-radius:0;border-bottom-left-radius:0;margin-bottom:-2px}.gg-home::after,.gg-home::before{content:"";display:block;box-sizing:border-box;position:absolute}.gg-home::before{border-top:2px solid;border-left:2px solid;border-top-left-radius:4px;transform:rotate(45deg);top:-5px;border-radius:3px;width:14px;height:14px;left:0}.gg-home::after{width:8px;height:10px;border:2px solid;border-radius:100px;border-bottom-left-radius:0;border-bottom-right-radius:0;border-bottom:0;left:3px;bottom:0}.gg-info{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:20px;height:20px;border:2px solid;border-radius:40px}.gg-info::after,.gg-info::before{content:"";display:block;box-sizing:border-box;position:absolute;border-radius:3px;width:2px;background:currentColor;left:7px}.gg-info::after{bottom:2px;height:8px}.gg-info::before{height:2px;top:2px}.gg-link{box-sizing:border-box;position:relative;display:block;transform:rotate(-45deg) scale(var(--ggs,1));width:8px;height:2px;background:currentColor;border-radius:4px}.gg-link::after,.gg-link::before{content:"";display:block;box-sizing:border-box;position:absolute;border-radius:3px;width:8px;height:10px;border:2px solid;top:-4px}.gg-link::before{border-right:0;border-top-left-radius:40px;border-bottom-left-radius:40px;left:-6px}.gg-link::after{border-left:0;border-top-right-radius:40px;border-bottom-right-radius:40px;right:-6px}.gg-list{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:22px;height:20px;border:2px solid;border-radius:3px}.gg-list::after,.gg-list::before{content:"";display:block;box-sizing:border-box;position:absolute;width:2px;height:2px;background:currentColor;top:3px;left:3px;box-shadow:0 4px 0,0 8px 0}.gg-list::after{border-radius:3px;width:8px;left:7px}.gg-math-minus{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:16px;height:2px;background:currentColor;border-radius:10px}.gg-slack{position:relative;box-sizing:border-box;transform:scale(var(--ggs,1));display:block;width:20px;height:20px;background:linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 7px 2px/2px 2px,linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 15px 7px/2px 2px,linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 2px 10px/2px 2px,linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 10px 15px/2px 2px,linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 10px 2px/4px 5px,linear-gradient(to left,currentColor 5px,transparent 0) no-repeat 5px 12px/4px 5px}.gg-slack::after,.gg-slack::before{background:currentColor;content:"";position:absolute;box-sizing:border-box;display:block;height:4px;border-radius:22px}.gg-slack::before{width:9px;top:5px;box-shadow:10px 5px 0}.gg-slack::after{width:4px;left:5px;box-shadow:-5px 10px 0,0 10px 0,0 15px 0,5px 15px 0,5px 5px 0,5px 0 0,10px 5px 0}.gg-sync{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));border-radius:40px;border:2px solid;margin:1px;border-left-color:transparent;border-right-color:transparent;width:18px;height:18px}.gg-sync::after,.gg-sync::before{content:"";display:block;box-sizing:border-box;position:absolute;width:0;height:0;border-top:4px solid transparent;border-bottom:4px solid transparent;transform:rotate(-45deg)}.gg-sync::before{border-left:6px solid;bottom:-1px;right:-3px}.gg-sync::after{border-right:6px solid;top:-1px;left:-3px}.gg-twitter{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:20px;height:20px}.gg-twitter::after,.gg-twitter::before{content:"";display:block;position:absolute;box-sizing:border-box;left:4px}.gg-twitter::before{width:9px;height:14px;border-left:4px solid;border-bottom:4px solid;border-bottom-left-radius:6px;background:linear-gradient(to left,currentColor 12px,transparent 0) no-repeat center 2px/10px 4px;top:4px}.gg-twitter::after{width:4px;height:4px;background:currentColor;border-radius:20px;top:2px;box-shadow:7px 4px 0,7px 12px 0}.gg-file-document{box-sizing:border-box;position:relative;display:block;transform:scale(var(--ggs,1));width:14px;height:16px;border:2px solid transparent;border-right:0;border-top:0;box-shadow:0 0 0 2px;border-radius:1px;border-top-right-radius:4px;overflow:hidden}.gg-file-document::after,.gg-file-document::before{content:"";display:block;box-sizing:border-box;position:absolute}.gg-file-document::before{background:currentColor;box-shadow:0 4px 0,-6px -4px 0;left:0;width:10px;height:2px;top:8px}.gg-file-document::after{width:6px;height:6px;border-left:2px solid;border-bottom:2px solid;right:-1px;top:-1px}</style><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),(()=>{var a="//matomo.jeaye.com/";_paq.push(["setTrackerUrl",a+"matomo.php"]),_paq.push(["setSiteId","1"]);var e=(p=document).createElement("script"),p=p.getElementsByTagName("script")[0];e.async=!0,e.src=a+"matomo.js",p.parentNode.insertBefore(e,p)})()</script><div><div><nav class="navbar is-primary"><div class="container"><div class="navbar-brand"><a class="navbar-item title has-text-white"href="/blog"style="font-family:Comfortaa"><img src="/img/logo-transparent.png"style="margin-right:15px">jank blog</a></div><div class="navbar-menu is-active"><div class="navbar-end has-text-weight-semibold"><a class="navbar-item has-text-white"href="/"><span class="icon mr-1"><i class="gg-home"></i></span><strong>Home</strong></a><a class="navbar-item has-text-white"href="https://book.jank-lang.org/"><span class="icon mr-1"><i class="gg-file-document"></i></span><strong>Documentation</strong></a><a class="navbar-item has-text-white"href="/blog"><span class="icon mr-1"><i class="gg-comment"></i></span><strong>Blog</strong></a><a class="navbar-item has-text-white"href="https://github.com/sponsors/jeaye"><span class="icon mr-1"style="color:#c96198"><i class="gg-heart"></i></span><strong>Sponsor</strong></a><a class="navbar-item has-text-white"href="https://github.com/jank-lang/jank"><span class="icon mr-1"><i class="gg-git-fork"></i></span><strong>Github</strong></a><a class="navbar-item has-text-white"href="https://clojurians.slack.com/archives/C03SRH97FDK"><span class="icon mr-1"><i class="gg-slack"></i></span>Slack</a><a class="navbar-item has-text-white"href="https://twitter.com/jeayewilkerson"><span class="icon mr-1"><i class="gg-twitter"></i></span>Twitter</a></div></div></div></nav></div><section class="section"><div class="container blog-container"><span class="is-size-1">jank is now running on LLVM IR</span><div class="is-size-6 has-text-weight-light">Nov 29, 2024 · <a class="has-text-weight-normal"href="https://github.com/jeaye">Jeaye Wilkerson</a></div><hr><div class="content"><p>Hi everyone! It's been a very busy couple of months as I've been developing jank's LLVM IR generation, improving jank's semantic analysis, and furthering jank's module loading system. Thank you to all of my Github sponsors and to Clojurists Together, who help me pay the bills. As of January 2025, I'll be working on jank full-time and every new sponsor means that much more. Without further ado, let's dive into the details of the past couple of months.<h2>LLVM IR</h2><p>The main focus of the past couple of months has been filling out jank's LLVM IR generation. This has required further improving some of its semantic analysis since I was previously able to cut some corners when generating C++ code.<p>At this point, all AST nodes in jank have working and tested IR generation except for <code>try</code>, since doing so requires hooking into the C++ runtime's unwind mechanism and I've been saving that rabbit hole for last.<p>IR generation has caused so many fun bugs the past couple of months that I had to look into a better way of organizing my notes for this quarter. There was just too much. When developing a language, especially in a pre-alpha stage like jank, when something crashes or is otherwise completely wrong, the issue could be anywhere from lexing to parsing to semantic analysis to code generation to object modeling to core function algorithms to data structures. I think there were some of each discovered in the past couple of months, but the majority of them were in the new IR generation.<h3>Named recursion</h3><p>One of the fun bugs I ran into was with how Clojure handles recursion through the function's own name. This doesn't go through the var; it just references the function object directly. The same applies with just a self-reference. For example:<pre class="shiki monokai"style="background-color:#272822;color:#f8f8f2"tabindex="0"><code><span class="line"><span style="color:#fd971f">(</span><span style="color:#fb4934;font-weight:700">fn</span><span style="color:#f8f8f2"> foo </span><span style="color:#fd971f">[]</span></span>
<span class="line"><span style="color:#f8f8f2">  foo</span><span style="color:#fd971f">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#fd971f">(</span><span style="color:#fb4934;font-weight:700">defn</span><span style="color:#f8f8f2"> foo </span><span style="color:#fd971f">[]</span></span>
<span class="line"><span style="color:#f8f8f2">  foo</span><span style="color:#fd971f">)</span></span></code></pre><p>In Clojure, and in jank with C++ generation, each function is an object (struct or class). A self-reference can literally just mean <code>this</code>. But with the LLVM IR generation, each function, and more specifically each function arity, is compiled to a dedicated C function. Aside from closures, which get an implicit first argument which is a generated struct of the captured values, the function itself has no other identifying state or object. This means a self-reference actually needs to build a new object. Previously, I would always just generate a local into each function like so:<pre class="shiki monokai"style="background-color:#272822;color:#f8f8f2"tabindex="0"><code><span class="line"><span style="color:#66d9ef;font-style:italic">auto</span><span style="color:#f8f8f2"> const foo</span><span style="color:#fd971f">{</span><span style="color:#fd971f"> this</span><span style="color:#fd971f"> }</span><span style="color:#f8f8f2">;</span></span></code></pre><p>Then I would register that local automatically during semantic analysis for functions. A self-reference would then just be a <code>local_reference</code> AST node. This can't carry over well to IR generation, so I've added two new AST nodes:<ol><li><code>recursion_reference</code>, which is created when we analyze that we're referring to the current function by name somewhere<li><code>named_recursion</code>, which is created when we're analyzing a <code>call</code> and find that the source expression is a <code>recursion_reference</code></ol><p>This does mean that a self-reference within a function wouldn't be <code>identical?</code> to the invoking object, but that's something we can document and otherwise really not care about.<h3>Startup performance</h3><p>Ultimately, the main reason for generating LLVM IR is that C++ is too slow to compile. If compiling <code>clojure.core</code> means generating 100K lines of C++ to compile, we end up waiting far too long for jank to start up. On my machine, it took around <strong>12 seconds</strong>.<p>Now, with IR generation, and a lot more functionality baked into jank itself, rather than JIT compiled, compiling <code>clojure.core</code> from source takes only <strong>2 seconds</strong>. This is fast enough to where we can easily include it as part of jank's build system. We can then pre-compile the sources to binaries and load those instead.<p>When I tried this with C++ generation, it took <strong>4 minutes</strong> to compile all of the C++ generated for <code>clojure.core</code> into a C++20 module with a backing shared library. It then took <strong>300ms</strong> to load at runtime, which dropped the start time from <strong>12 seconds</strong> to <strong>300ms</strong>. That AOT compilation cost was huge, but the gain was also big.<p>With IR generation, we can also generate object files. Amazingly, it can be done within the same <strong>2 seconds</strong> used to compile <code>clojure.core</code> in the first place. When loading that object file at runtime, jank can now start up in <strong>150ms</strong>. So, we spend a fraction of the time actually compiling the code and even less time loading it. Overall, for startup performance, LLVM IR has been a huge win. This is exactly what I wanted and I'm very pleased with the results.<p><div class="figure"><figure><object data="/img/blog/2024-11-29-llvm-ir/startup-time.plot.svg"type="image/svg+xml"><img src="/img/blog/2024-11-29-llvm-ir/startup-time.plot.svg"></object></figure></div><p><p>Note, when all of this is baked into the executable AOT, startup time is around <strong>50ms</strong>. jank doesn't support AOT compilation of full programs yet, but I've manually added the object files to jank's CMake build in order to test this out. Once we do have AOT compilation to binaries, we can also add direct linking, link-time optimizations (LTO), etc. and drop these numbers down even further.<h3>Runtime performance</h3><p>Runtime performance will be negatively impacted by IR generation, at least to start. The C++ code jank used to generate was quite optimized. I was taking advantage of various C++ features, like function overloading, type inference, and easy (yet ambiguous) unboxing of numerical values. With IR gen, we need to do all of those manually, rather than rely on a C++ compiler to help. This will take more work, but it also allows us to tailor the optimizations to best fit jank.<p>I'm not ready to report any benchmark results for runtime performance differences yet, since I don't think measuring the initial IR generation against the previous C++ generation is a good usage of time. Optimizing IR can happen as we go, without breaking any ABI compatibility. I'm more focused on getting jank released right now.<h2>Build system and portability improvements</h2><p>Apart from working on LLVM IR generation the past couple of months, I've put a fair amount of time into improving jank's builds system and dependency management. In particular, vcpkg has been removed entirely. I was using vcpkg to bring in some C and C++ source dependencies, but some of them regularly fail to build from source on very normal setups and vcpkg on its own causes issues with build systems such as Nix. Altogether, it's well known that the build system and dependency tooling for C and C++ is terrible. While I aim for jank to improve that, in its own way, we still need to suffer through it for the compiler itself.<p>In order to remove vcpkg, I had to address all of the dependencies it was pulling in.<ul><li>bdwgc (Boehm GC) requires compilation<ul><li>Added a submodule and hooked into CMake<li><a href="https://github.com/ivmai/bdwgc/pull/675">Required a PR for CMake compatibility</a></ul><li>fmt requires compilation<ul><li>Added a submodule and hooked into CMake</ul><li>libzipp requires compilation<ul><li>Added a submodule and hooked into CMake</ul><li>immer is header-only<ul><li>Added a submodule</ul><li>magic_enum is header-only<ul><li>Added a submodule</ul><li>cli11 is header-only<ul><li>Added a submodule</ul><li>doctest is in all major package repos<li>boost is in all major package repos<ul><li><code>boost::preprocessor</code> isn't found by CMake on Ubuntu, but it's there<ul><li>Doesn't exist in brew's package, though<li>Had to add as a submodule</ul><li>Causes Clang to crash while building <code>incremental.pch</code></ul></ul><p>All in all, this required <strong>seven new git submodules</strong>. Even something as commonplace as boost led to dependency issues across various platforms. I did all of my testing on Ubuntu, Arch, NixOS, and macOS. Once I had all of those submodules, I still ran into some issues with Clang hard crashing while trying to compile an incremental pre-compiled header (PCH) with boost. This was the final straw with PCHs for me.<h3>Pre-compiled headers</h3><p>jank started out with PCHs from the beginning. I was concerned about compile-times and I knew that many source files would need access to the whole object model in order to compile. While this remains true, I didn't expect that PCHs would be such a headache when JIT compiling C++. There have been a handful of Cling bugs and then Clang bugs related to loading PCHs into the incremental C++ environment. I've spent entire days compiling Clang/LLVM while bisecting in order to find root causes. <a href="https://github.com/jank-lang/jank/pull/94">Haruki</a> has been so close to building jank on Nix but has been running into issues when compiling the incremental PCH. This has been a long time coming.<p>After removing the PCHs, fixing all source files to include what they need, refactoring some heavy headers so they can be used less often, and running some tooling to further clean things up, we can wipe our hands of all of that. jank does still need to JIT compile C++ code, but it can do so using both a C API and a C++ API. Devs using jank can include what they need.<p>Previously, just loading the incremental PCH with all of jank's headers took a whopping 2.5 seconds every start up and we always paid that cost. Now, better following the (intended) nature of C++, we can pay for what we use.<h2>Community update</h2><p>I have not been the only one working on jank. The past couple of months, my newest mentee through the <a href="https://scicloj.github.io/docs/community/groups/open-source-mentoring/">SciCloj mentorship program</a>, <a href="https://github.com/stmonty">Monty Bichouna</a>, has wrapped up Unicode lexing support. This allows jank the important ability to properly represent Unicode symbols and keywords. Monty's work builds on Saket's recent work to add Unicode support for character objects.<p>To further jank's interop story, <a href="https://github.com/Samy-33">Saket Patel</a> also recently merged some changes which allow jank to accept include paths, linker paths, and linked shared libraries. This means that you can now include other C and C++ libraries from your JIT compiled bridge code and have the JIT linker resolve those symbols in your libraries. In other words, <strong>it's now possible to use jank to wrap arbitrary C and C++ libraries</strong>. Saket took this further by adding an opaque pointer wrapper object which can store any non-owned native pointer to be passed through any jank function and stored in any jank data structure. Each of these is a small step toward a much richer interop story. Saket also added persistent history to jank's CLI REPL and improved its usability by hooking into LLVM's line editing capabilities.<p><a href="https://github.com/jianlingzhong">Jianling Zhong</a> added support for ratio objects in jank, including the whole polymorphic math treatment necessary for them. He also implemented jank's delay object and corresponding <code>clojure.core/delay</code> macro as well as jank's repeat object, which backs the <code>clojure.core/repeat</code> function.<p>Finally, <a href="https://github.com/quoll">Paula Gearon</a> has been making excellent progress on a sister project to jank, <a href="https://github.com/jank-lang/clojure.core-test">clojure.core-test</a>, which is a cross-dialect test suite for all of <code>clojure.core</code>. Ultimately, my goal with this is to aid Clojure dialect developers by providing a thorough test suite for Clojure's core functions. By being able to run and pass this suite, my confidence in jank will be strong. I'm sure other dialect developers will feel similarly.<h2>What's next?</h2><p>I need to fix a couple remaining bugs with the LLVM IR generation and then implement IR generation for <code>try</code> nodes, in the next couple of weeks. After that, the next big goal is error reporting. This is an exciting task to tackle, since the impact of it is going to feel so rewarding. I have been suffering jank's terrible error messages for years. Even worse, we as an industry have been suffering terrible error messages for decades. There's been some exciting progress in <a href="https://elm-lang.org/news/compiler-errors-for-humans">Elm</a>, <a href="https://blog.rust-lang.org/2016/08/10/Shape-of-errors-to-come.html">Rust</a>, etc for improving the way errors are reported, providing actionable feedback, and including sufficient context to make errors less cryptic. I don't think that Clojure does well in this area, currently, and I aim to raise the bar.<p>If that sounds interesting, stay tuned for my next update!<h2>Would you like to join in?</h2><ol><li>Join the community on <a href="https://clojurians.slack.com/archives/C03SRH97FDK">Slack</a><li>Join the design discussions or pick up a ticket on <a href="https://github.com/jank-lang/jank">GitHub</a><li>Considering becoming a <a href="https://github.com/sponsors/jeaye">Sponsor</a> <span class="icon mr-1"style="color:#c96198"><i class="gg-heart"></i></span><li><strong>Better yet, hire me full-time to work on jank!</strong></ol></div></div></section></div><footer class="footer"><div class="container"><div class="columns has-text-centered"></div><div class="container has-text-centered"><div class="content is-small"><p>© 2025 Jeaye Wilkerson | All rights reserved.</div></div></div></footer><noscript><p><img src="//matomo.jeaye.com/matomo.php?idsite=1&amp;rec=1"style="border:0"alt=""></p></noscript><script>for(var coll=document.getElementsByClassName("collapsible"),i=0;i<coll.length;i++)coll[i].addEventListener("click",function(){this.classList.toggle("active");var l=this.nextElementSibling;"block"===l.style.display?l.style.display="none":l.style.display="block"})</script>